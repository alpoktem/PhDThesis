%**************** Introduction **************
\chapter{Introduction}
\label{chapter:intro}

%From spoken to written language. 
Written form of communication is much more modern to the human than spoken communication. Even though it also constitutes a lesser fraction of the ways how humans communicate, it still is the basis of both traditional and computational linguistic studies. This is largely thanks to the discrete form that language took with the invention of the symbology to represent it. This symbology took many forms in time, earlier as images, icons and colors, later utilizing abstract characters that assemble words, sentences within grammatical structures that constitute what we define as written language. This conversion of paradigm in language facilitated the recording, diffusion, study and automated processing of the human-made information. 

%Rich information in speech: prosody
Compared to written language, spoken language inherently carries more information than its linguistic content. In speech, linguistic units like words are enveloped within properly divided measures, accompanied with a certain melody that has its highs and lows and even delivered with a rhythm. These ``music-like'' aspects, which are defined as the \textit{prosody} in language, deals with \textit{how} a certain utterance is delivered. Through the prosodic structure of the language we are able to tell things both about the speaker and the information they want to transmit. Besides helping us understand the structure in their discourse, it helps to understand, for example, which sort of a mode they are in, if they are being serious or ironic, or where to direct our attention. 

%Encoding language to text
Even though an encoding through this modality of speech seems missing in the written form of the language, it inherently accompanies it both on the way to being written and being read \citep{wallace}. To demonstrate, as I am writing these words, I imagine explaining my thoughts to the reader with my inner voice prosody. In turn, I trust their own inner voices to enact what I am trying to say and form the same thoughts which I aim to transmit. Although there seems to be no way of marking the prosodic style in written language, words still resonate within ones own melody.

%Encoding language to text means loss of information. However written language covers for it. 
However, one can notice the information loss during the conversion of spoken language to written language. The reader can only guess how I want this discourse to sound like, and that guess might as well be completely different than what I intend. If they do not know me personally, this guess could only be influenced by the general prosodic structure of the language (English in this case) the reader was exposed to with a bias on their own way of expressing it. 

Written language gives only a limited set of tools to convey the information which would normally be encoded with prosody in spoken language. An example to these tools is punctuation. It helps structure intonational phrasing, indicates modalities like question and exclamation, marks subordinate information flow and so on. This role of punctuation, i.e. substituting prosody\footnote{Early works on English grammar like \cite{lowth} for example relates punctuation usage directly to prosody. Periods and commas were marks of pauses, one double the length of the other. Exclamation and question mark were used for a rise in intonation. Parantheses was used to mark a depressed tonality and so on.}, has evolved in time and established through grammatical rules and now is considered only partially affected by prosodic structure in language. In fact, written language in general, has evolved from spoken language so that a neutral prosody is sufficient in transferring of information through this limited symbology, thus minimizing the loss during the conversion. 

%Machines use symbols to communicate just like in written communication
Because of its discrete structure, written language has been much more convenient for machines to process since human has taught them ways to understand their language. This technological breakthrough, which is defined as natural language processing (NLP), has opened ways to collaborate with machines to solve tasks such as translation, information extraction and speech-to-text and text-to-speech conversion. These tasks can now be seen applied in great number of ways like spoken/written dialogue systems, automatic captioning, speech-to-speech translation, sentiment analysis and so on. As machines function by using a pre-defined set of symbols, language in its written form dominates most of these applications. Even in the cases where there is spoken language involved, machines rely on a step where speech has to be converted to text in order to carry on with the subsequent processes in the pipeline. 

Just like explained earlier, this conversion means a loss of a dimension in the language caused by the limited representation of it. An automatic speech transcription (ASR) system acting as the interface to these type of technologies merely transcribes "what is being said?" and disregards any information related to "how is it being said?". This eventually affects the understanding of the communicative intention as a whole in spoken language. If we desire to have machines understanding us in a complete way like humans do, this information residing in prosody needs to be processed besides the linguistic information.
This means integration of modelling of prosodic phenomena with modelling of linguistic phenomena. However, because of the non-discrete and suprasegmental structure of prosody this is viewed as a challenging problem. 

% %neural networks
% Recent years showed a shift towards the use of neural-network based systems for solving NLP tasks. Complex systems 


% a shift towards neural-network based systems used in NLP tasks. 
% discrete set -> vector space. 
% effectiveness of RNNs in modelling


\section{Motivation}

%Focus areas: (1) ASR and (2) SLMT
The work presented in this dissertation is motivated by two primal applications that involve conversion of speech into written form: Automatic speech transcription and spoken language machine translation. The former involves conversion of speech to its written form and is applied in many type of applications such as dictation systems, automatic captioning and spoken dialogue systems. Spoken language machine translation (SLMT) involves automatic speech transcription as its first step but further translates the transcription into a second language and in some cases synthesize it. Its uses include, for example, automatic subtitling and automatic dubbing. While automated transcription facilitates indexing, tagging and accessibility for the hearing-impaired, automatic translation methodologies help reduce language barriers in accessing the global information. This type of technology is already very relevant due to their recently gained success in handling well a variety types of data. The user-created videos in YouTube\footnote{\url{http://youtube.com}} for example can be viewed with automatically created captions. Through automated transcription services, these captions can be translated on the go and presented aligned to the video. 

The recent advancement in automated processing of natural languages owes much to the application of neural networks for these tasks. Although the core technology behind neural networks is not new, it has only recently started being preferred against older probabilistic methods. This was largely due to the rise in computational power that made possible the training and applicability of the systems that use \textit{deep neural networks (DNNs)}. Its use for language modelling was demonstrated in 2001 \citep{Bengio:LM}, for automatic speech recognition (ASR) in 2012 \citep{asr_dnnhmm} and machine translation (MT) in 2014 \citep{sutskever}. Popularly used machine translation service \textit{Google Translate}\footnote{\url{http://translate.google.com}} was converted to work with this type of architecture from 2016 on \citep{google_nmt}. 

%Motivation and a short intro to prosody
The motivation of this dissertation is to explore ways to incorporate prosodic features of speech into neural-network based systems that involve spoken language understanding. As sketched in the introductory section, the current tendency in these type of systems is carrying on with text processing once spoken input is converted to written form. This causes an irreversible loss of the information which is essential in human communication. This information is encoded through suprasegmental features of speech which are intonation, tone, duration and rhythm and contributes to the para-linguistic content of communication. Examples of this para-linguistic structures are: phrasing that helps structure discourse, emphasis, modality defining if the communication is a question, assertion, exclamation or command, information structure that defines givenness etc. 

My specific motivations in this aspect within the frame of this dissertation can be grouped into three main topics: (1) prosodic data compilation, (2) punctuation restoration in speech transcripts and (3) machine translation enhancement with prosody. I will examine further my motivations for these specific topics in the upcoming subsections. 

\subsection{Prosodic Data Compilation}
%Prosodic data collection
Key to machine learning-driven development is directly related to the availability of quality data. It shows that, development of speech data annotated with acoustic/prosodic features shows two main challenges. The first challenge is posed by the suprasegmental and multidimensional structure of prosody which makes alignment of linguistic and acoustic features difficult. Although some toolkits exist that assists prosodic annotation of speech data \citep{Rosenberg10}, they fall short in terms of applicability in machine learning based approaches. Second challenge is caused by the nature of prosody being directly influenced from context and environment where speech is taking place. Data collected in laboratory environments often fail in reflecting expressivity normally present in spoken language, and in turn, influence models to bias on unnatural data. To aid collection of expressive speech data, a form of harvesting ``found data'' that accommodates prosodic annotation is needed. Scalable methods to process, visualize and store this type of data is also necessary in developing data-driven methodologies.

\subsection{Punctuation Restoration in Speech Transcripts}
%ASR/punctuation motivation
The process of automatic speech transcription involves use of an ASR system to convert the spoken input to text. The raw text output of an ASR system generally lacks any form of punctuation. Depending on the application, punctuation proves to be important for two reasons: First, in the cases where transcriptions will be read by humans, lack of punctuation reduces readability to a large extent. This is demonstrated in the work of \cite{Tundik2018} where watchers of broadcast news were asked to compare punctuated and unpunctuated captions. Both for manually and automatically created transcriptions, punctuated transcriptions were preferred in helping follow the video content. Second case where punctuation has an important role is when the ASR output is further used in subsequent processes like machine translation or parsing. Both these processes require sentence-like units as input and cannot function with long unsegmented text. Furthermore, commas and other punctuation marks that are defined within the orthography of a language prove to be important cues for machines to understand text, similar to the case of humans \citep{Cho2017NMTbasedSA, Jones:1994:ERP:991886.991960}. Although rules of punctuation is formally defined within the grammatical and orthographic rules of a language, spoken language punctuation is predominantly related with prosody \cite{wallace}. Sentence structures and phrasing are often marked with intonational phrasing and breaks. Modality influences the intonation style of a sentence which in turn influences punctuation. Topic changes are generally marked with intensity and pitch resets. Emphasized information is often delivered with a change in pitch or breaking. 

Looking at raw ASR output, which consists of only the linguistic content, is often not enough in determining punctuation especially in cases of spontaneous speech. This type of speech often does not follow a regular syntactic structure as in written language, thus making it difficult to determine punctuation based on syntactic or data-driven methods that are modeled for written text \citep{ballesterosneural}. Neural network-based work that gets use of prosodic cues report improvement in accuracy of the punctuation marks generated \citep{tilk2016bidirectional}, but still rely on huge chunks of textual data thus biasing models on written language. Also, there is no study reporting the effect of a wider variety of prosodic features into the task. 

\subsection{Machine Translation Enhancement with Prosody}
%Translation motivation
Spoken language machine translation (SLMT) is a type of machine translation architecture where input and/or output to the system is spoken language. In the text-input setup, prosody is relevant for capturing the sentence structure and phrasing which in turn affects translations. In spoken-output systems the need to convey the prosodic structure into the synthesized speech appears in applications such as automatic dubbing. In both setups, a prosodic modelling of the input speech is needed to avoid the information loss at the recognition step. Prosodic transfer modelling was previously explored in a number of works \citep{aguero2006prosody, Quoc2018, anumanchipalli:2012}. The data used in these approaches are collected in laboratory conditions, meaning that recordings are prompted, and almost always are based on travel domain. There is no previous study that takes on a domain that involves more expressive speech such as movies or TV shows. Especially in these domains, there is a rich source of prosodic varieties that affect both translations for subtitling and dubbing. 

\section{Objectives}
Revolving around the motivation that prosody should be incorporated in technology that involves spoken language understanding, I have assigned the following objectives for the course of my research:

\begin{itemize}
    \item Development of tools that enable creation, prosodic annotation, handling and visualization of spoken language data, based on open sourced resources and publicly available,
    \item Development of an automated methodology for creating monolingual and bilingual prosodically annotated corpora from prosodically rich found data,
    \item Compilation and publication of monolingual and bilingual corpora suitable for machine learning based development that involves prosodic-linguistic modelling,
    \item Evaluation on the effect of various prosodic features on the task of automatic punctuation restoration and subsequent automatized processes like parsing and machine translation,
    \item Evaluation on the use of raw prosodic features on the task of spoken language machine translation, with a focus on movie domain.
\end{itemize}

My hypothesis is that systems that take spoken language as input will benefit through the recovering of the lost prosodic information during the conversion of speech into text. The aim is not only to prove this but also examine the behaviour in these types of systems utilizing neural network-based architectures. 

%Experiments based on neural nets 
\section{Outlining the Dissertation}

This dissertation is structured in six chapters as follows:

\begin{itemize}
    \item \textbf{Chapter 2} first gives an overview on speech processing systems encompassing the motivated applications of this dissertation. Emphasis is given on deep neural network based setups. Second, state-of-the-art work that deal with the encoding of prosody in relation to my motivated topics is presented. 
    \item \textbf{Chapter 3} presents corpus related work. Tools that were developed and utilized for prosodic data compilation and visualization is presented. Also, two corpora that were used and published within this dissertation's frame are explained in detail. 
    \item \textbf{Chapter 4} focuses on the theme of punctuation restoration in raw speech transcripts with a focus on the use of prosodic features and their effects on recovery performance, parsing and with an ASR system. 
    \item \textbf{Chapter 5} explores the use of prosodic features within a neural spoken machine translation setting. An expressive parallel corpus collected from a TV series is used to do prosodic adaptation on movie-domain translation. Incorporation of prosody into both the encoding and decoding modules of a speech-to-speech translation pipeline is experimented.
    \item \textbf{Chapter 6} puts the final conclusions on the thesis in terms of the objectives reached and also outlines possible venues for future research and applications. 
\end{itemize}


