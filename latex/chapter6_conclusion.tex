%**************** conclusions ****************

\chapter{Conclusions and Future work}
\label{chapter:conclusion}

In this dissertation, I have addressed the motivation for the inclusion of prosodic modelling in systems with spoken input. Initially, I have tried to give a general perspective on the issue while explaining my motivation for this work. As it is not only the linguistic content but also the para-linguistic content encoded through prosody that counts in human communication, machines should also pay attention to it in processing natural languages in their spoken form. 

Within the development of speech processing technologies, focus is given into the extraction and transformation of the linguistic content. Prosody, which has an important linguistic and para-linguistic role in communication is generally not given the attention it deserves. 

Defined within this broad perspective, I have argued and demonstrated my point specifically on two main applications that process spoken language: automatic speech transcription and spoken language translation. In the former one, I focused my attention on the effect prosody has on the punctuation of the resulting transcription. In the latter one, I experimented on the inclusion of pause features on both input and output of a sequence-to-sequence neural translation pipeline, with a focus on movie domain. To accommodate both of these data-driven approaches, a number of toolkits were developed for the creation, processing, handling and visualization of speech data annotated with acoustic-prosodic features. Using these toolkits, two prosodically annotated speech corpora have been published, one of them being the first example in the highly expressive movie domain. 

This chapter is organized as follows: I will give final conclusions regarding the developments and experiments conducted within the framework of this dissertation in Section \ref{conclusions:conclusions}. Next, I will sketch a road map for future work in Section \ref{conclusions:future}. Finally, the achievements that are the results of the work in this dissertation and attributions are given in Section \ref{conclusions:achievements}.

\section{Conclusions}
\label{conclusions:conclusions}

The motivation to enhance speech related methodologies with prosodic modelling comes with a cost and that mostly resides in the labour of data harvesting. It is notable the portion of the work given in this dissertation on development of methodologies to collect naturally expressive speech data and shape them to be processed in machine learning-based applications. A complete pipeline for collecting, handling, annotation, storage and visualization of prosodic data has been presented. \textit{Proscript} library, which was developed for acoustic-prosodic annotation of transcripted speech data, served a basis for the experimentation presented. Regarding collection of large datasets, \textit{Prosograph} was developed as a side project that served greatly in manual examination of prosodic corpora. It was seen that there was a lot to learn from the data itself during the design of machine learning-based systems that process prosody. Nature of prosody shows that it is worth its own set of toolkit for examination and studying. Prosograph addresses this with its easily programmable interface that helps visualization of speech related characteristics in huge portions of spoken data. 

I furthermore addressed the lack of availability of expressive parallel speech corpora to the scientific community. A novel methodology was developed for exploiting the readily available parallel speech data residing in dubbed movies. This framework was utilized for obtaining a parallel English-Spanish expressive speech dataset from a TV series. Heroes corpus, which consists of 7000 parallel audio segments with transcriptions and annotated prosodic features, is made openly available. This is to my knowledge first example of a corpus containing a rich variety of prosodic characteristics and is bilingually structured. The experiments carried out using this corpus demonstrated that dubbed movies can serve as a valuable resource for cross-lingual prosodic studies and developing prosodically motivated translation methodologies. 

A part of this dissertation focused on the topic of punctuation as it was seen as the closest form of symbology in written text that is influenced by prosody. It serves for various functions including marking boundaries in discourse, modality in communication (question, affirmation, exclamation etc.), resolving ambiguity, etc., all of which is partially encoded with prosody in spoken language. Output of speech recognition interfaces lack this form of symbology that proves to be essential for both humans and machines in processing of the transcript. 

I have presented a novel methodology that employs lexical and prosodic features in a neural network-based framework for the task of punctuation restoration in speech transcripts. The framework was designed to work with purely spoken data to avoid the dominance of written language, which is the case in previous works. Moreover, it made possible the integration of any desired feature (lexical, syntactic or prosodic) and thus enabled the evaluation of effect of various features on the task. Experiments that were conducted on a corpus of conference talks showed that combination of the word, POS, inter-lexical pause and pitch features worked best for the accurate restoration of the three principal punctuation marks: period, comma and question mark. The setup that performs best among three punctuation marks obtained an $F_1$ score of 70.3\% which showed an improvement of 3.5\% compared to the baseline approach when only spoken data was used. Furthermore, for individual punctuation marks, $F_1$ scores of 83\%, 71.8\% and 55.2\% were reported employing various other feature combinations. Period had a tendency to benefit from the use of intensity features. Commas were detected generally with low accuracy but showed that use of pitch features helped. The low scoring of commas was explained with the possible variance in punctuation annotation in the reference transcripts. Although pitch features were expected to help detection of question marks, it did not show any improvement with its inclusion. This signals the need for a better modelling of pitch features in the framework as future work. As an architecture choice, converting continuous prosodic features to discrete levels on input improved the results in general. 

The punctuation recovery models obtained with this approach gave promising results also when employed within a framework where an automatic speech recognition system was employed. This was demonstrated in an interactive setup employing a commercial large vocabulary automatic speech recognition system and Prosograph.

Effect of prosody in punctuation restoration modelling was tested on two subsequent processes: dependency parsing and machine translation. The former evaluation was conducted on a small dataset and showed that accounting of prosody does imply an improvement in correct parsing of the sentences. An improvement of 5\% was recorded with lexical feature-based punctuation restoration of unpunctuated sentences in terms of labelled attachment score. This was further improved by 0.7\% when lexical-prosodic punctuation restoration was employed. This shows that commas, which are detected more accurately with prosodic models, do show improvement in parsing despite their low detection accuracy. 

%translation
The final set of experiments presented in the dissertation involved spoken language machine translation (SLMT) based on movie domain. My motivation was to incorporate prosodic input and output into a neural machine translation pipeline, exploring ways to improve automatic subtitling and dubbing. Example-based and statistical study showed agreement of prosodic phenomena in dubbed segments of the expressive parallel speech dataset (Heroes corpus). Focus was given to inter-lexical silent pauses as a prosodic phenomena in both these studies and the methodology proposed. I introduced a neural machine translation framework that was able to take prosodic input and output besides the lexical information to be translated. This framework that I call \textit{TransProse}, was used for exploring these three questions: (1) How does prosodic punctuation restoration affect translation?, (2) Does pause encoding improve translation? and (3) Can pauses be translated jointly with lexical information? 

Regarding the first question, it showed that a prosodic punctuation restoration step prior to translation serves to improve translation quality. A known technique to recover for missing punctuation in input phrases of a SLMT system is to train models that learn to translate from unpunctuated to punctuated sentences. Translation using this technique taken as baseline worked better than performing lexical feature-based punctuation restoration beforehand. However, when prosodic features were employed in the punctuation restoration process, an improvement of 0.5\% was recorded in terms of BLEU scoring compared to the baseline technique. This experiment showed that encoding of prosodic features in a MT pipeline, through a process of punctuation restoration, can help in improving translation quality. 

I explored my second question regarding the effect of pause encoding in translation by setting the TransProse framework to do joint encoding of inter-lexical silent pauses with lexical information. This setup was tested on two types of input in terms of punctuation: First input set contained manually placed punctuation while the second input set contained automatically restored punctuation to emulate a real SLMT setup where ASR output is unpunctuated. Translation of both test sets showed an improvement in terms of translation quality with the encoding of the pauses. First set showed an improvement of 1.31\% and the second an improvement of 1.07\% in terms of BLEU scores. The results of this experiment showed that encoding of prosody, even within a limited dimension, can indeed benefit automatic translation.  
The third and final question was motivated from the use-case of automatic dubbing of movies and TV-shows. Dubbing involves carefully timed acting of dialogues in a movie to make it accessible to foreign language viewers. A speech-to-speech translation system designed to be used in such an application needs to take heed of prosody in the translation and dubbings in order to capture the para-linguistic features of actors lines. Usage of inter-lexical pause features is explored in this aspect. 

To evaluate this, I set up a translation framework that both encodes and decodes pauses. Each output token in this setup carries a pause flag output for the purpose of cuing the TTS system that a pause needs to be placed after that token. A small test-set had to be built especially for this experiment as it proved to be difficult to assess the right placement of a pause in inaccurate translations. Some meaningful pausings were observed in this test set, however no generalized pattern was discovered. A selection from this samples with ``well-transferred'' pausings were synthesized using a TTS system that takes prosodic labels. The perception tests involving these samples showed that although prosodic translation models perform better in terms of text translation, in terms of synthesis, they were not preferred. The synthesized samples were deemed as even more ``robotic'' with the pausings introduced isolated from other prosodic characteristics. Future work on this aspect need research on a better interface with a TTS system. 

\section{Future Work}
\label{conclusions:future}

As a follow-up to the work in this dissertation, a variety of research lines and also applications can be mentioned. With respect to parallel data collection methodologies, a more systematic approach can be followed employing collaboration with dubbing companies. Cleaner and larger corpora can be obtained by development of processes incorporated in the dubbing process itself. 

An improvement on the automatic prosodic feature annotation toolkit could be labelling of filled pauses. The current setup only accounts for silent pauses easily obtained from word alignments. An extension on the word alignment software could be made to exploit phoneme durations. Modelling of filled pauses would benefit both prosodic punctuation recovery and prosodically enhanced machine translation. 

The prosodic punctuation restoration framework introduced in this dissertation is planned to be integrated within an open source Catalan speech recognition system \citep{Kulebi2018}. This will give the opportunity to compare the prosody-punctuation interfaces between the languages English and Catalan. However, the low performing comma detection needs to be addressed in future work. As it is a punctuation mark that is defined mostly within grammatical rules, it suggests the hybrid integration of a syntactically-oriented approach. Also, modelling of intonation features can be improved by having a higher precision of sampling of pitch movements. Having pitch aligned to linguistic information on syllable or phoneme level can work better in this sense. 

Applications that automate captioning, subtitling and dubbing will be even more relevant once an acceptable quality is achieved in real-world applications. Prosodic modelling for these applications is still a virgin area to be discovered. For this reason, TransProse framework opens many doors for future research. However, there is work to be done before thinking on how to improve the prosodic modelling on the network. First and foremost, the main lesson gained from the experiments was that a baseline for good text translation is crucial before thinking to make prosodic enhancements on the pipeline. This will be the first objective in near future on this aspect. More recent NMT approaches like Transformer \citep{transformer}, which report better performance, could be applied. Another problem faced was that the text training corpus employed was sub-optimal. A base corpus with less noise and more literal translations is central for having a good text translation baseline. Also methodologies that adapt better to spoken domain by training on incomplete sentences could help \citep{niehues2018}. 

It showed that dubbed movies as a spoken language translation resource is a less explored area. There are many features of dubbing, like matching lip movements,  sentence lengths etc. that makes it interesting for computational modelling. The fact that dubbing artists pay much attention to the re-enacting of paralinguistic aspects cross-lingually is a phenomena that could be studied more carefully. My near future research includes more analyses on the position of matching long  pauses. This is a feature that is more or less directly transferred in dubbing for matching lip movements. It hints that automatic modelling of this transfer could be more straightforward. It showed that two types of pauses, silent and filled, often were used in the place for the other in the dubbed translations. It would be beneficial to look into ways to annotate this on Heroes corpus and incorporate them in future experiments. 

Also, it would be very interesting to see voice conversion \citep{Turk, Kaneko} and style transfer techniques \citep{style_tokens} in this application area. The former techniques are used to transfer spectral characteristics between two speech recordings. Some recent work include cross-lingual transfer as well \citep{crosslingual}. Applying these techniques could make the synthesized dubbings closer to the voices of the original actors. Style tokens represent prosodic features in embeddings to be used for encoding prosodic style of a speaker in end-to-end TTS. A similar method could be employed cross-linguistically.  

I have learned from my final experiment with TransProse framework that having a complete speech-to-speech pipeline needs more attention on text-to-speech systems. Inputting prosodic features as external SSML tags did not improve but even made the final audio samples sound worse. The cohesion between MT and TTS has to be improved by putting more focus on the parameters that TTS uses for prosodic modelling.

\section{Achievements and Attributions}
\label{conclusions:achievements}

This section lists publications, datasets and software created by the author during the course of the work presented in this dissertation. Finally, I will list the attributions that are relevant to the work carried out. 

\subsection{Publications}
\label{conclusions:publications}
A number of papers were successfully published in peer-reviewed conferences that cover some of the work presented. Portions from these work were used during the writing of this dissertation. Below lists these publications together with the related ones that the author contributed:

\begin{itemize}
\item Öktem, A., Farrús, M., Bonafonte, A. \textit{Bilingual Prosodic Dataset Compilation for Spoken Language Translation.} Proc. IberSPEECH 2018, October 25-29 2018, Barcelona, Spain.

\item Külebi, B., Öktem, A., \textit{Building an Open Source Automatic Speech Recognition System for Catalan}. Proc. IberSPEECH 2018, October 25-29 2018, Barcelona, Spain.

\item Öktem A, Farrús M, Bonafonte A., \textit{Visualizing Punctuation Restoration in Speech Transcripts with Prosograph}. Proc. Interspeech 2018, p. 1493-4, Sep 2-6 2018, Hyderabad, India.

\item Öktem A, Farrús M, Wanner L. \textit{Punctuating Transcribed Speech Using Lexical and Prosodic Cues via Attentional Parallel RNNs.} (Under review) Computer Speech and Language. Elsevier.

\item Öktem A, Farrús M, Wanner L., \textit{Attentional Parallel RNNs for Generating Punctuation in Transcribed Speech}. In: Camelin N, Estève Y, Martín-Vide C. Statistical Language and Speech Processing. 5th International Conference SLSP 2017; 2017 Oct 23-25; Le Mans, France. Cham: Springer, 2017. p. 131-42. (LNCS; no. 10583 ). DOI: 10.1007/978-3-319-68456-7\_11

\item Burga A, Öktem A, Wanner L., \textit{Revising the METU-Sabancı Turkish treebank: an Exercise in Surface-syntactic Annotation of Agglutinative Languages.} In: Montemagni S, Nivre J, editors. Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017); 2017 Sept 18-20; Pisa, Italy. ACL; 2017. p. 32-41.

\item Öktem A, Farrús M, Wanner L., \textit{Prosograph: A Tool for Prosody Visualisation of Large Speech Corpora}. In: Proceedings of the 18th Annual Conference of the International Speech Communication Association (INTERSPEECH 2017),p. 809-10, Stockholm, Sweden: ISCA; 2017. 

\item Öktem A, Farrús M, Wanner L., \textit{Automatic Extraction of Parallel Speech Corpora from Dubbed Movies}. In Proceedings of the 10th Workshop on Building and Using Comparable Corpora (BUCC), p. 31-35, Vancouver, Canada: ACL, 2017. 

\end{itemize}

\subsection{Datasets}
\label{conclusions:datasets}
Both datasets that were compiled during the work in this dissertation are published openly for the use of the research community. They are listed below with their short description:

\begin{itemize}
    \item \textbf{TED Talks Corpus} - TED talks are a set of conference talks lasting in average 15 minutes each that have been held worldwide in more than 100 languages. They include a large variety of topics, from technology and design to science, culture and academia. The corpus consists of 1038 talks by 877 English speakers, uttering a total amount of 155174 sentences. The corresponding transcripts, as well as audio and video files, are available on TED's website\footnote{\url{http://www.ted.com}}. This dataset is a recompiled version of the dataset used in \cite{Farrus:SP:2016}.
    LINK: \url{http://hdl.handle.net/10230/33981}
    
    \item \textbf{Heroes Corpus} - Heroes Corpus contains mapped bilingual (English and Spanish) speech segments from the TV series Heroes. It contains 7000 single speaker speech segments extracted from the original and Spanish dubbed version of 21 episodes. Audio segments are accompanied with subtitle transcriptions and word-level prosodic/paralinguistic information. Audio portions are taken respecting fair use. 
    LINK: \url{http://hdl.handle.net/10230/35572}
\end{itemize}

\subsection{Software Resources}
\label{conclusions:software}

All software related to the work in this dissertation was developed with the mindset that another researcher would like to reproduce its results or improve them. Below is the list of repositories that contain the source code used in the experiments:

\begin{itemize}
    \item \textbf{movie2parallelDB} - Automatic parallel speech database extractor from dubbed movies. LINK: \url{https://github.com/TalnUPF/movie2parallelDB}
    \item \textbf{Prosograph} - A Visualizer for prosodically annotated speech corpora written with Processing. LINK: \url{https://github.com/TalnUPF/Prosograph}
    \item \textbf{PunkProse} - A library for punctuation generation for speech transcripts using lexical and prosodic features. LINK: \url{https://github.com/TalnUPF/punkProse}
    \item \textbf{Proscript} - A Python package to help create proscript files. Proscript helps represent speech with annotated prosody. The library carries automatic annotation scripts that are based on Praat. LINK: \url{https://github.com/alpoktem/proscript}
    \item \textbf{TED talks corpus preprocessing scripts} - A library for creating a trainable corpus from the prosodically annotated TED corpus prepared by Mireia Farrús and Catherine Lai. LINK: \url{https://github.com/alpoktem/ted_preprocess}
    \item \textbf{Prosodic punctuation generation demo on ASR} - This is a demo software that contains scripts to punctuate audio recordings using punkProse library. It is intended to use for demonstration purposes. LINK: \url{https://github.com/alpoktem/punkProse_ASR-demo}
    \item \textbf{TransProse} - A framework based on sequence-to-sequence neural networks for translation with prosodic features. LINK: \url{https://github.com/alpoktem/TransProse}
\end{itemize}


\subsection{Attributions}

I will list in this section the attributions relevant to the work presented in this dissertation (with no particular order):

\begin{itemize}
    \item Special thanks to annotators Sandra Marcos Bonet and Laura G\'omez Fisas for their collaboration during the Spanish subtitle correction process for the development of Heroes Corpus. 
    \item The author received the 2018 Maria de Maeztu Reproducibility Award from Department of Information and Communication Technologies of Universitat Pompeu Fabra for his presentation ``Generating punctuation in Transcribed Speech: Combining lexical and prosodic features using parallel recurrent networks.'' The prize was partially used to finance the Heroes corpus compilation work. 
    \item NVIDIA Corporation has kindly donated a Titan Xp GPU to be used in training the translation models presented in Chapter \ref{chapter:transProse}.
    \item The author has received full-time scholarship from Department of Information and Communication Technologies of Universitat Pompeu Fabra throughout his doctoral study. 
    \item Work related to prosodic punctuation restoration presented in Chapter \ref{chapter:corpusWorks} and \ref{chapter:punkProse} was developed for this project for the European Union project KRISTINA, which received funding from the \textit{European Union's Horizon 2020 Research and Innovation Programme} under the Grant Agreement number 645012.
    \item Linguistic analyses on punctuation and prosody in Chapter \ref{chapter:punkProse} were carried out in collaboration with Dr. Mónica Domínguez and Dr. Alicia Burga.  
    \item Some parts of the work presented in Chapter \ref{chapter:corpusWorks} and \ref{chapter:punkProse} were done in collaboration with Dr. Leo Wanner. 
\end{itemize}
