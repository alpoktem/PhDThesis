%**************** conclusions ****************

\chapter{Conclusions and Future work}
\label{chapter:conclusion}

In this dissertation, I have addressed the motivation for the inclusion of prosodic modelling in systems with spoken input. Initially, I have tried to give a general perspective on the issue while explaining my motivation for this work. As it is not only the linguistic content but also the para-linguistic content encoded through prosody that counts in human communication, machines should also pay attention to it in processing natural languages in their spoken form. 

%By machines, I mean the constantly increasing computational methods that help humans in many tasks that involve understanding our own ways of communication. This intelligence can already be seen in applications ranging from virtual assistants to automatic transcription and translation systems. Moreover, its growth promises that it will be ubiquitous in near future to have systems understanding and interacting as humans do. 

Within the development of speech processing technologies, focus is given into the extraction and transformation of the linguistic content. Prosody, which has an important linguistic and para-linguistic role in communication is generally not given the attention it deserves. 

%Automatic speech recognition (ASR) systems that cover the interface to these technologies Recent work that showed great progress in speech recognition and machine translation through the rise of deep neural network based methods, focus merely on the recognition and transfer of the linguistic content. There is relatively a smaller number of studies exploring approaches including para-linguistic content that speech prosody carries.

Defined within this broad perspective, I have argued and demonstrated my point specifically on two main applications that processes spoken language: automatic speech transcription and spoken language translation. In the former one, I focused my attention on the effect prosody has on the punctuation of the resulting transcription. In the latter one, I experimented on the inclusion of pause features on both input and output of a sequence-to-sequence movie domain translation pipeline. To accommodate both of these data-driven approaches, a number of toolkits were developed for the creation, processing, handling and visualization of speech data annotated with acoustic/prosodic features. Using these toolkits, two prosodically annotated speech corpora has been published, one of them being the first example in the highly expressive movie domain. 

This chapter is organized as follows: I will give final conclusions regarding the developments and experiments conducted within the framework of this dissertation in Section \ref{conclusions:conclusions}. Next, I will sketch a road map for future work in Section \ref{conclusions:future}. Finally, the contributed artifacts that are the results of the work in this dissertation is given in three sections: publications in Section \ref{conclusions:publications}, datasets in Section \ref{conclusions:datasets} and open source software resources in Section \ref{conclusions:software}.

\section{Conclusions}
\label{conclusions:conclusions}

The motivation to enhance speech related methodologies with prosodic modelling comes with a cost and that mostly resides in the field of data harvesting. It is notable the portion of the work given in this dissertation only involved in development of methodologies to collect naturally expressive speech data and shape them to be processed in machine learning-based applications. A complete pipeline for collecting, handling, annotation, storage and visualization of prosodic data has been developed. \textit{Proscript} library, which was developed for acoustic/prosodic annotation of transcripted speech data, served a basis for the experimentation presented. Regarding collection of large datasets, \textit{Prosograph} was developed as a spin-off framework which served greatly in manual examination of this type of data. It was seen that there was a lot to learn from the data itself during the design of machine learning-based systems that process prosody. Nature of prosody shows that it is worth its own set of toolkit for examination and studying. Prosograph addressed this with its easily programmable interface that helped visualization and interaction of speech related characteristics in huge portions of spoken data. 

I furthermore addressed the lack of availability of expressive parallel speech corpora to the scientific community. A novel methodology was utilized for obtaining a parallel English-Spanish speech dataset with acoustic/prosodic annotations called \textit{Heroes Corpus}. This is to my knowledge first example of a corpus containing a rich variety of prosodic characteristics and is bilingually structured. Furthermore, this demonstrated that dubbed movies can serve as a valuable resource for collecting data to serve in prosodically motivated translation methodologies. 

A part of this dissertation focused on the topic of punctuation as it was seen as the closest form of symbology in written text that is influenced by prosody. It serves for various functions including marking boundaries in discourse, modality in communication (question, affirmation, exclamation etc.), resolving ambiguity etc. all of which is partially encoded with prosody in spoken language. Output of speech recognition interfaces lack this form of symbology which proves to be essential for both humans and machines in processing of the transcript. Punctuation recovery for speech transcripts uses syntactic and/or prosodic features to address this. However, it was seen that previous works bias more on written data and do not report on the effect of individual prosodic features to the task.

An application oriented approach was followed by taking a state-of-the-art RNN-based punctuation recovery system as basis and expanding it to handle more types of prosodic features that were available through a corpus based on conference talks. Experiments that were conducted on purely spoken data showed that combination of the word, POS, inter-lexical pause and pitch features worked best for the accurate detection of punctuation marks in general. The proposed architecture that processed lexical and prosodic features in parallel and trained on one pass achieved a significant improvement compared to the baseline approach when only spoken data was used. An F-score of 83\%, 71.8\% and 55.2\% was obtained with various feature combinations in accurate restoration of periods, question marks and commas respectively. The punctuation recovery models obtained with this approach gave promising results also when employed within a framework where an automatic speech recognition (ASR) system was employed. 

Effect of prosody in punctuation restoration modelling was tested on two subsequent processes: dependency parsing and machine translation. The former evaluation was conducted on a small dataset and showed that accounting of prosody does imply an improvement in correct parsing of the sentences. This shows that commas which are detected more accurately with prosodic models does improve parsing despite its low F-score. Within a spoken language machine translation framework, punctuation restoration that was applied as a preprocessing step before machine translation gave better results with the inclusion of prosodic modelling. 

Finally, a machine translation framework that is able to take prosodic input and output was developed for the sake of proving the effect of prosody in spoken language translation. Experiments were based on translation in movie domain with the motivation to build prosody-aware automatic subtitling and dubbing systems. It showed that inclusion of inter-word pauses as an additional feature on the encoding side of a sequence-to-sequence translation system could improve translation quality. Furthermore, experiments regarding joint word-prosody output gave some hopeful results for further research on incorporation of prosody transfer modelling in speech-to-speech translation. Conclusions drawn from the suboptimal results indicate that availability of more parallel data and adapted TTS architectures are essential for building joint prosodic-lexical translation models. 

\section{Future Work}
\label{conclusions:future}

As follow-up to the work in this dissertation, a variety of research lines and also applications can be mentioned. With respect to parallel data collection methodologies, a more systematic approach can be followed employing collaboration with dubbing companies. Cleaner and larger corpora can be obtained by development of processes incorporated in the dubbing process itself. 

The prosodic punctuation restoration framework introduced in this dissertation is planned to be integrated within an open source Catalan speech recognition pipeline \citep{Kulebi2018}. This will give the opportunity to compare the prosody-punctuation interfaces between the languages English and Catalan. However, the low performing comma detection needs to be addressed in future work. As it is a punctuation mark that is defined mostly within grammatical rules, it suggests the integration of a hybrid rule-based modelling approach. Also, modelling of intonation features can be improved by having a higher precision of sampling of pitch movements. Having pitch aligned to linguistic information on syllable or phoneme level can work better in punctuation recovery. 

Applications that automate captioning, subtitling and dubbing will be even more relevant once an acceptable quality is achieved in real-world applications. Prosodic modelling for these applications is still a virgin area to be discovered. Style tokens \citep{style_tokens} that achieve conveying of prosodic style between speakers can be useful in getting synthesis closer to acting. 

\section{List of Publications}
\label{conclusions:publications}
A number of papers were successfully published in peer-reviewed conferences that cover some of the work presented in this dissertation. Below lists these publications together with the related ones that the author contributed:

\begin{itemize}
\item Öktem, A., Farrús, M., Bonafonte, A. \textit{Bilingual Prosodic Dataset Compilation for Spoken Language Translation.} Proc. IberSPEECH 2018, October 25-29 2018, Barcelona, Spain.

\item Külebi, B., Öktem, A., \textit{Building an Open Source Automatic Speech Recognition System for Catalan}. Proc. IberSPEECH 2018, October 25-29 2018, Barcelona, Spain.

\item Öktem A, Farrús M, Bonafonte A., \textit{Visualizing Punctuation Restoration in Speech Transcripts with Prosograph}. Proc. Interspeech 2018, p. 1493-4, Sep 2-6 2018, Hyderabad, India.

\item Öktem A, Farrús M, Wanner L. \textit{Punctuating Transcribed Speech Using Lexical and Prosodic Cues via Attentional Parallel RNNs.} (Under review) Computer Speech and Language. Elsevier.

\item Öktem A, Farrús M, Wanner L., \textit{Attentional Parallel RNNs for Generating Punctuation in Transcribed Speech}. In: Camelin N, Estève Y, Martín-Vide C. Statistical Language and Speech Processing. 5th International Conference SLSP 2017; 2017 Oct 23-25; Le Mans, France. Cham: Springer, 2017. p. 131-42. (LNCS; no. 10583 ). DOI: 10.1007/978-3-319-68456-7\_11

\item Burga A, Öktem A, Wanner L., \textit{Revising the METU-Sabancı Turkish treebank: an Exercise in Surface-syntactic Annotation of Agglutinative Languages.} In: Montemagni S, Nivre J, editors. Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017); 2017 Sept 18-20; Pisa, Italy. ACL; 2017. p. 32-41.

\item Öktem A, Farrús M, Wanner L., \textit{Prosograph: A Tool for Prosody Visualisation of Large Speech Corpora}. In: Proceedings of the 18th Annual Conference of the International Speech Communication Association (INTERSPEECH 2017),p. 809-10, Stockholm, Sweden: ISCA; 2017. 

\item Öktem A, Farrús M, Wanner L., \textit{Automatic Extraction of Parallel Speech Corpora from Dubbed Movies}. In Proceedings of the 10th Workshop on Building and Using Comparable Corpora (BUCC), p. 31-35, Vancouver, Canada: ACL, 2017. 

\end{itemize}

\section{List of Datasets}
\label{conclusions:datasets}
Both datasets that were compiled during the work in this dissertation are published openly for the use of the research community. They are listed below with their short description:

\begin{itemize}
    \item \textbf{TED Talks Corpus} - TED talks are a set of conference talks lasting in average 15 minutes each that have been held worldwide in more than 100 languages. They include a large variety of topics, from technology and design to science, culture and academia. The corpus consists of 1038 talks by 877 English speakers, uttering a total amount of 155174 sentences. The corresponding transcripts, as well as audio and video files, are available on TED's website\footnote{\url{http://www.ted.com}}. This dataset is a recompiled version of the dataset used in \cite{Farrus:SP:2016}.
    LINK: \url{http://hdl.handle.net/10230/33981}
    
    \item \textbf{Heroes Corpus} - Heroes Corpus contains mapped bilingual (English and Spanish) speech segments from the TV series Heroes. It contains 7000 single speaker speech segments extracted from the original and Spanish dubbed version of 21 episodes. Audio segments are accompanied with subtitle transcriptions and word-level prosodic/paralinguistic information. Audio portions are taken respecting fair use. 
    LINK: \url{http://hdl.handle.net/10230/35572}
\end{itemize}

\section{List of Software Resources}
\label{conclusions:software}

All software related to the work in this dissertation were developed with the mindset that another researcher would like to reproduce its results or improve them. Below is the list of repositories that contain the source code used in the experiments:

\begin{itemize}
    \item \textbf{movie2parallelDB} - Automatic parallel speech database extractor from dubbed movies. LINK: \url{https://github.com/TalnUPF/movie2parallelDB}
    \item \textbf{Prosograph} - A Visualizer for prosodically annotated speech corpora written with Processing. LINK: \url{https://github.com/TalnUPF/Prosograph}
    \item \textbf{PunkProse} - A library for punctuation generation for speech transcripts using lexical and prosodic features. LINK: \url{https://github.com/TalnUPF/punkProse}
    \item \textbf{Proscript} - A Python package to help create proscript files. Proscript helps represent speech with annotated prosody. The library carries automatic annotation scripts that are based on Praat. LINK: \url{https://github.com/alpoktem/proscript}
    \item \textbf{TED talks corpus preprocessing scripts} - A library for creating a trainable corpus from the prosodically annotated TED corpus prepared by Mireia Farrús and Catherine Lai. LINK: \url{https://github.com/alpoktem/ted_preprocess}
    \item \textbf{Prosodic punctuation generation demo on ASR} - This is a demo software that contains scripts to punctuate audio recordings using punkProse library. It is intended to use for demonstration purposes. LINK: \url{https://github.com/alpoktem/punkProse_ASR-demo}
    \item \textbf{TransProse} - A framework based on sequence-to-sequence neural networks for translation with prosodic features. LINK: \url{https://github.com/alpoktem/TransProse}
\end{itemize}

